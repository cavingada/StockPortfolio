{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSMIF Quant Coding Challenge\n",
    "# Author: Cavin Gada\n",
    "\n",
    "\"\"\" IMPORTS \"\"\"\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "\n",
    "    \"\"\" to make this class usable for a broader purpose, I allow the constructor to take in different \n",
    "    values to build a portfolio to the user's liking. The default values are the specifics the assignment wants.\n",
    "    \"\"\"\n",
    "    def __init__(self, start = datetime.datetime(2021, 1, 1), end = datetime.datetime(2021, 12, 31), tickers = ['KO', 'TSLA', 'SPY']):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.tickers = tickers\n",
    "        self.treasury_yield_10_year = .0412 # we'll use this as the risk free rate\n",
    "        self.df = (web.DataReader(self.tickers, 'yahoo', start = self.start, end = self.end)['Adj Close']).dropna()\n",
    "    \n",
    "    def getDailyReturns(self, ticker):\n",
    "        return ((self.df[ticker]/self.df[ticker].shift(1))-1).dropna() # shift allows us to divide the next day by previous\n",
    "\n",
    "    @staticmethod\n",
    "    def getDailyVolatility(returns):\n",
    "        return returns.rolling(window=2).std(ddof=0) # we'd like to calculate a running volatility (based on the next day's info). we are NOT looking for total volatility. \n",
    "\n",
    "    def statistics(self, a = 0.05):\n",
    "        # comparing means of daily returns using two-sided T-test\n",
    "        KO_RETURNS = self.getDailyReturns('KO')\n",
    "        TSLA_RETURNS = self.getDailyReturns('TSLA')\n",
    "\n",
    "        returns_t_value, returns_p_value = stats.ttest_ind(KO_RETURNS,TSLA_RETURNS) # two tailed t test\n",
    "        \n",
    "        KO_VOLATILITIES = self.getDailyVolatility(KO_RETURNS)\n",
    "        TSLA_VOLATILITIES = self.getDailyVolatility(TSLA_RETURNS)\n",
    "\n",
    "        # Comparing volatilities using two-sided F-test. We use an F-test since we are comparing standard deviations (volatilities)\n",
    "        f = np.var(TSLA_VOLATILITIES, ddof=1)/np.var(KO_VOLATILITIES, ddof=1) # calculate F-statistic (higher variance in numerator)\n",
    "        df1 = TSLA_VOLATILITIES.size-1 \n",
    "        df2 = KO_VOLATILITIES.size-1\n",
    "        volatility_p_value =  2 * (1-stats.f.cdf(f, df1, df2)) # we are performing a two-tailed test, thus, need to multiply the tail area twice\n",
    "\n",
    "        return returns_p_value, volatility_p_value\n",
    "\n",
    "    def valueAtRisk(self, meanDailyReturn, stdDailyReturn, tolerance = 0.95):\n",
    "        return stats.norm.ppf(1-tolerance, meanDailyReturn, stdDailyReturn) # essentially just an inverse cdf to find the value at which the significance hits on the normal curve.\n",
    "\n",
    "    def annualizedSharpeRatio(self, meanDailyReturn, stdDailyReturn):\n",
    "        # The returns of the portfolio are a Wiener process, in which volatility scales with the square-root of time\n",
    "        # reference: https://medium.datadriveninvestor.com/the-sharpe-ratio-with-python-from-scratch-fbb1d5e490b9#:~:text=Evaluating%20a%20Stock's%20Risk%20with%20Python&text=Any%20Sharpe%20Ratio%20above%201.00,3.00%20is%20considered%20very%20good.\n",
    "        # take mean of daily returns and subtract it by the mean daily return of the benchmark (in this case we have the 10 year treasury bond in 2021 divided by 252 to get a daily compounding rate)\n",
    "        # divide by the standard deviation and multiply by sqrt(number of trading days) to annualize it. \n",
    "        return (meanDailyReturn-self.treasury_yield_10_year/252)/(stdDailyReturn) * np.sqrt(252) \n",
    "    \n",
    "    def downsideDeviation(self, returns):\n",
    "\n",
    "        # used https://www.investopedia.com/terms/d/downside-deviation.asp as a guide for calculating the downside deviation\n",
    "        minimumAccpetableRate = self.treasury_yield_10_year / 252 # we divide by 252 since we assume the daily rate stays constant for the yearly rate of 1.59%\n",
    "        returnsMinusMAR = pd.Series(returns - minimumAccpetableRate) # must ensure its a direct series in order to call loc. we want to get the difference between stock return and RFR rate\n",
    "        returnsBelowZero = returnsMinusMAR.loc[lambda x : x < 0] # we only want the downside values (negatives, meaning the return was less than the RFR)\n",
    "        sumOfSquaredReturns = np.sum(np.square(returnsBelowZero)) # square each return and take the sum \n",
    "        downsideDeviation = np.sqrt(sumOfSquaredReturns/returnsMinusMAR.size) # divide by the total number of returns and take the square root to find the DD\n",
    "        return downsideDeviation\n",
    "        \n",
    "    def maximumDrawdown(self, prices, window=252):\n",
    "        # shoutout to: https://medium.com/cloudcraftz/measuring-maximum-drawdown-and-its-python-implementation-99a3963e158f\n",
    "        # last time I implemented this function, I used more complex logic where I analyzed the globa max/min and local max/mins before or after.\n",
    "        # this resource helped implement the max drawdown in easier to read and more simplistic code\n",
    "        Roll_Max = prices.rolling(window,min_periods=1).max() # over the course of the year, set rolling on 1 day intervals and calculate the max\n",
    "        Daily_Drawdown = prices/Roll_Max - 1.0 # calculate the losses at each point from its relative rolling max\n",
    "        Max_Daily_Drawdown = Daily_Drawdown.rolling(window, min_periods=1).min() # calculate the 'smallest' gain or the greatest loss\n",
    "        return Max_Daily_Drawdown.iat[-1] # we can take the lat value in the df instead of searching for the min since we know the last value is the minimum due to the rolling\n",
    "    \n",
    "    def metrics(self, ticker = \"KO\", tolerance = .95):\n",
    "\n",
    "        dailyReturns = self.getDailyReturns(ticker)\n",
    "        meanDailyReturn = np.mean(dailyReturns)\n",
    "        stdDailyReturn = np.std(dailyReturns)\n",
    "\n",
    "        averageDailyVolatility = self.getDailyVolatility(dailyReturns).mean()\n",
    "        valueAtRisk = self.valueAtRisk(tolerance, meanDailyReturn, stdDailyReturn) \n",
    "        annualizedSharpeRatio = self.annualizedSharpeRatio(meanDailyReturn, stdDailyReturn)\n",
    "        downsideDeviation = self.downsideDeviation(dailyReturns)\n",
    "        maxDrawdown = self.maximumDrawdown(self.df[ticker])\n",
    "        \n",
    "        return averageDailyVolatility, valueAtRisk, annualizedSharpeRatio, downsideDeviation, maxDrawdown\n",
    "\n",
    "    def capm(self, ticker = \"TSLA\"):\n",
    "        # resource used to find polyfit: https://www.mlq.ai/capital-asset-pricing-model-python/\n",
    "        beta, alpha = np.polyfit(self.getDailyReturns('SPY'), self.getDailyReturns(ticker), 1)\n",
    "        return beta,alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Statistics()\n",
      "\n",
      "\n",
      "Is there a statistically significant difference in the mean daily returns?\n",
      "To test for a significant difference in mean daily returns, I used a Student's t-test. To perform this test, I am assuming that the observations in each sample are: independent and identically distributed, randomly sampled, normally distributed, and have the same variance.\n",
      "p-value: 0.525039\n",
      "result: because the p-value is greater than the significance level of 0.05, we fail to reject the null hypothesis, meaning that there is no significant difference between the mean daily returns of the two equities\n",
      "\n",
      "\n",
      "Is there a statistically significant difference in their volatilities?\n",
      "To test for a significant difference in volatilities, I used an F-test. To perform this test, I am assuming that the observations in each sample are: independent and identically distributed, approximately normally distributed, and have the same population variance. I'm also comparing standard deviations and the data may be skewed.\n",
      "p-value: 2.220446e-16\n",
      "result: because the p-value is less than the significance level of 0.05, we reject the null hypothesis, meaning that there is a significant difference between the volatilities of the two equities\n",
      "\n",
      "\n",
      "metrics()\n",
      "Volatility: 0.005107 (this value represents the average amount by which the returns may swing from the mean on a daily basis, it measures risk)\n",
      "95 Pecent Value at Risk (VaR): 0.951475 (this value represents the max amount expected (with 95 percent confidence) to be lost over the next day)\n",
      "Sharpe Ratio: 0.792128 (this value measures the performance of an investment compared to a risk-free asset, after adjusting for its risk. A ratio of just under 1 indicates that risk of holding the equity is just not quite offsetting its return.)\n",
      "Downside Deviation: 0.006643 (this value measures how risky an investment may be if the upside deviation is 'safer' or less risky than it seems. It only looks at the downside risk)\n",
      "Maximum Drawdown: -0.087377 (this value measures the most by which a stock dropped between two chronological points on the timeline, in this case the largest drop in value was 8.7 percent)\n",
      "\n",
      "\n",
      "capm()\n",
      "Beta: 1.954511 (this value refers to relative volatility of the investment. At a score of 2, the beta indicates that the equity value is very volatile and risky)\n",
      "Alpha: -0.000078 (this value refers to the amount returned in comparison to the market (SPY). Since the value is at about 0, it seems that the return was on par with the benchmark)\n"
     ]
    }
   ],
   "source": [
    "p1 = Portfolio()\n",
    "\n",
    "print(\"Part 1: Statistics()\")\n",
    "\n",
    "returns_p_value, volatility_p_value = p1.statistics() \n",
    "volatility_p_value_scientific=\"{:e}\".format(volatility_p_value)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Is there a statistically significant difference in the mean daily returns?\")\n",
    "print(\"To test for a significant difference in mean daily returns, I used a Student's t-test. To perform this test, I am assuming that the observations in each sample are: independent and identically distributed, randomly sampled, normally distributed, and have the same variance.\")\n",
    "print(\"p-value: %f\" % (returns_p_value))\n",
    "print(\"result: because the p-value is greater than the significance level of 0.05, we fail to reject the null hypothesis, meaning that there is no significant difference between the mean daily returns of the two equities\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Is there a statistically significant difference in their volatilities?\")\n",
    "print(\"To test for a significant difference in volatilities, I used an F-test. To perform this test, I am assuming that the observations in each sample are: independent and identically distributed, approximately normally distributed, and have the same population variance. I'm also comparing standard deviations and the data may be skewed.\")\n",
    "print(\"p-value: %s\" % (volatility_p_value_scientific))\n",
    "print(\"result: because the p-value is less than the significance level of 0.05, we reject the null hypothesis, meaning that there is a significant difference between the volatilities of the two equities\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"metrics()\")\n",
    "averageDailyVolatility, valueAtRisk, annualizedSharpeRatio, downsideDeviation, maxDrawdown = p1.metrics()\n",
    "print(\"Volatility: %f (this value represents the average amount by which the returns may swing from the mean on a daily basis, it measures risk)\" % (averageDailyVolatility))\n",
    "print(\"95 Pecent Value at Risk (VaR): %f (this value represents the max amount expected (with 95 percent confidence) to be lost over the next day)\" % (valueAtRisk))\n",
    "print(\"Sharpe Ratio: %f (this value measures the performance of an investment compared to a risk-free asset, after adjusting for its risk. A ratio of just under 1 indicates that risk of holding the equity is just not quite offsetting its return.)\" % (annualizedSharpeRatio))\n",
    "print(\"Downside Deviation: %f (this value measures how risky an investment may be if the upside deviation is 'safer' or less risky than it seems. It only looks at the downside risk)\" % (downsideDeviation))\n",
    "print(\"Maximum Drawdown: %f (this value measures the most by which a stock dropped between two chronological points on the timeline, in this case the largest drop in value was 8.7 percent)\" % (maxDrawdown))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"capm()\")\n",
    "beta, alpha= p1.capm()\n",
    "print(\"Beta: %f (this value refers to relative volatility of the investment. At a score of 2, the beta indicates that the equity value is very volatile and risky)\" % (beta))\n",
    "print(\"Alpha: %f (this value refers to the amount returned in comparison to the market (SPY). Since the value is at about 0, it seems that the return was on par with the benchmark)\" % (alpha))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d339a2a8c50b423644d93202ec801c8d3e3572f2d49108f6f93dfd237da3c203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
